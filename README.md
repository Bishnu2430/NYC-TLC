# NYC TLC Big Data Analytics with Hadoop & Spark

A comprehensive big data project analyzing NYC Taxi & Limousine Commission (TLC) trip data using Apache Hadoop and Apache Spark on Ubuntu.

## ğŸš€ Project Overview

This project demonstrates:
- Large-scale data processing using Hadoop HDFS
- Real-time analytics with Apache Spark
- Distributed computing on taxi trip data
- Performance optimization techniques
- Data visualization and insights

## ğŸ—ï¸ Architecture

NYC TLC Data Pipeline
Raw Parquet â†’ HDFS â†’ Spark Processing â†’ Analytics & Visualization

## ğŸ“Š Dataset

- **Source**: NYC TLC Trip Record Data (2025)
- **Format**: Apache Parquet
- **Size**: ~10+ million records per month
- **Features**: Trip duration, distance, fares, locations, congestion pricing

## ğŸ› ï¸ Tech Stack

- **Storage**: Hadoop HDFS 3.3.6
- **Processing**: Apache Spark 3.5.6
- **Resource Management**: YARN
- **Language**: Python (PySpark)
- **Visualization**: Matplotlib, Seaborn
- **Environment**: Ubuntu 22.04

## ğŸ“ Repository Structure

nyc-tlc-big-data-project/
â”œâ”€â”€ scripts/              # Analysis and processing scripts
â”œâ”€â”€ config/               # Hadoop/Spark configuration files
â”œâ”€â”€ docs/                 # Documentation and guides
â”œâ”€â”€ notebooks/            # Jupyter notebooks
â”œâ”€â”€ data-samples/         # Small sample datasets
â”œâ”€â”€ results/              # Analysis outputs and visualizations
â””â”€â”€ README.md
